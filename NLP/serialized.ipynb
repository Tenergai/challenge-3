{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 01:45:06.356709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 01:45:07.446499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import typing\n",
    "from typing import Any, Tuple\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class ShapeChecker():\n",
    "  def __init__(self):\n",
    "    # Keep a cache of every axis-name seen\n",
    "    self.shapes = {}\n",
    "\n",
    "  def __call__(self, tensor, names, broadcast=False):\n",
    "    if not tf.executing_eagerly():\n",
    "      return\n",
    "\n",
    "    parsed = einops.parse_shape(tensor, names)\n",
    "\n",
    "    for name, new_dim in parsed.items():\n",
    "      old_dim = self.shapes.get(name, None)\n",
    "      \n",
    "      if (broadcast and new_dim == 1):\n",
    "        continue\n",
    "\n",
    "      if old_dim is None:\n",
    "        # If the axis name is new, add its length to the cache.\n",
    "        self.shapes[name] = new_dim\n",
    "        continue\n",
    "\n",
    "      if new_dim != old_dim:\n",
    "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
    "                         f\"    found: {new_dim}\\n\"\n",
    "                         f\"    expected: {old_dim}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_lower_and_split_punct(text):\n",
    "  # Split accented characters.\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
    "  text = tf.strings.lower(text)\n",
    "  # Keep space, a to z, and select punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿0-9]', '')\n",
    "  # Add spaces around punctuation.\n",
    "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
    "  # Strip whitespace.\n",
    "  text = tf.strings.strip(text)\n",
    "\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
    "  return text\n",
    "\n",
    "def masked_loss(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction='none')\n",
    "    loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "    # Mask off the losses on padding.\n",
    "    mask = tf.cast(y_true != 0, loss.dtype)\n",
    "    loss *= mask\n",
    "\n",
    "    # Return the total.\n",
    "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "\n",
    "def masked_acc(y_true, y_pred):\n",
    "    # Calculate the loss for each item in the batch.\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
    "    \n",
    "    match = tf.cast(y_true == y_pred, tf.float32)\n",
    "    mask = tf.cast(y_true != 0, tf.float32)\n",
    "    \n",
    "    return tf.reduce_sum(match)/tf.reduce_sum(mask)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def get_config(self):\n",
    "    config = {\n",
    "        'text_processor': self.text_processor,\n",
    "        'units': self.units\n",
    "    }\n",
    "    base_config = super().get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "  \n",
    "  def __init__(self, text_processor, vocab_size, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = vocab_size\n",
    "    self.units = units\n",
    "    \n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
    "                                               mask_zero=True)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform'))\n",
    "      \n",
    "  def call(self, x):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch s')\n",
    "\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 3. The GRU processes the sequence of embeddings.\n",
    "    x = self.rnn(x)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "def convert_input(encoder, texts):\n",
    "  texts = tf.convert_to_tensor(texts)\n",
    "  if len(texts.shape) == 0:\n",
    "    texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "  context = encoder.text_processor(texts)\n",
    "  context = context.to_tensor()\n",
    "  context = encoder(context)\n",
    "  return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n",
    "\n",
    "  def call(self, x, context):\n",
    "    shape_checker = ShapeChecker()\n",
    " \n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(context, 'batch s units')\n",
    "\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "    \n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(attn_scores, 'batch heads t s')\n",
    "    \n",
    "    # Cache the attention scores for plotting later.\n",
    "    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
    "    shape_checker(attn_scores, 'batch t s')\n",
    "    self.last_attention_weights = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\n",
    "            'text_processor': self.text_processor,\n",
    "            'vocab': self.vocab,\n",
    "            'vocab_size' : self.vocab_size,\n",
    "            'units': self.units\n",
    "        }\n",
    "    base_config = super().get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "  \n",
    "  def __init__(self, text_processor, vocab, vocab_size, units):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab = vocab\n",
    "    self.vocab_size = vocab_size\n",
    "    self.word_to_id = tf.keras.layers.StringLookup(\n",
    "        vocabulary=self.vocab,\n",
    "        mask_token='', oov_token='[UNK]')\n",
    "    self.id_to_word = tf.keras.layers.StringLookup(\n",
    "        vocabulary=self.vocab,\n",
    "        mask_token='', oov_token='[UNK]',\n",
    "        invert=True)\n",
    "    self.start_token = self.word_to_id('[START]')\n",
    "    self.end_token = self.word_to_id('[END]')\n",
    "\n",
    "    self.units = units\n",
    "\n",
    "\n",
    "    # 1. The embedding layer converts token IDs to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
    "                                               units, mask_zero=True)\n",
    "\n",
    "    # 2. The RNN keeps track of what's been generated so far.\n",
    "    self.rnn = tf.keras.layers.GRU(units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    # 3. The RNN output will be the query for the attention layer.\n",
    "    self.attention = CrossAttention(units)\n",
    "\n",
    "    # 4. This fully connected layer produces the logits for each\n",
    "    # output token.\n",
    "    self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
    "    \n",
    "  def call(self, context, x, state=None, return_state=False):  \n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch t')\n",
    "    shape_checker(context, 'batch s units')\n",
    "\n",
    "    # 1. Lookup the embeddings\n",
    "    x = self.embedding(x)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 2. Process the target sequence.\n",
    "    x, state = self.rnn(x, initial_state=state)\n",
    "    shape_checker(x, 'batch t units')\n",
    "\n",
    "    # 3. Use the RNN output as the query for the attention over the context.\n",
    "    x = self.attention(x, context)\n",
    "    self.last_attention_weights = self.attention.last_attention_weights\n",
    "    shape_checker(x, 'batch t units')\n",
    "    shape_checker(self.last_attention_weights, 'batch t s')\n",
    "\n",
    "    # Step 4. Generate logit predictions for the next token.\n",
    "    logits = self.output_layer(x)\n",
    "    shape_checker(logits, 'batch t target_vocab_size')\n",
    "\n",
    "    if return_state:\n",
    "      return logits, state\n",
    "    else:\n",
    "      return logits\n",
    "\n",
    "  def get_initial_state(self, context):\n",
    "    batch_size = tf.shape(context)[0]\n",
    "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
    "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
    "    embedded = self.embedding(start_tokens)\n",
    "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]\n",
    "\n",
    "  def tokens_to_text(self, tokens):\n",
    "    words = self.id_to_word(tokens)\n",
    "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
    "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
    "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
    "    return result\n",
    "\n",
    "  def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
    "    logits, state = self(\n",
    "      context, next_token,\n",
    "      state = state,\n",
    "      return_state=True) \n",
    "    \n",
    "    if temperature == 0.0:\n",
    "      next_token = tf.argmax(logits, axis=-1)\n",
    "    else:\n",
    "      logits = logits[:, -1, :]/temperature\n",
    "      next_token = tf.random.categorical(logits, num_samples=1)\n",
    "\n",
    "    # If a sequence produces an `end_token`, set it `done`\n",
    "    done = done | (next_token == self.end_token)\n",
    "    # Once a sequence is done it only produces 0-padding.\n",
    "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
    "    \n",
    "    return next_token, done, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator(tf.keras.Model):\n",
    "  @classmethod\n",
    "  def add_method(cls, fun):\n",
    "    setattr(cls, fun.__name__, fun)\n",
    "    return fun\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {\n",
    "            'units': self.units,\n",
    "            'context_text_processor': self.context_text_processor,\n",
    "            'context_vocab_size' : self.context_vocab_size,\n",
    "            'target_text_processor': self.target_text_processor,\n",
    "            'target_vocab': self.target_vocab,\n",
    "            'target_vocab_size': self.target_vocab_size\n",
    "        }\n",
    "    base_config = super().get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "  \n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "      return cls(**config)\n",
    "\n",
    "  def __init__(self, units,\n",
    "               context_text_processor, context_vocab_size,\n",
    "               target_text_processor, target_vocab, target_vocab_size):\n",
    "    super().__init__()\n",
    "    # Build the encoder and decoder\n",
    "    encoder = Encoder(context_text_processor, context_vocab_size, units)\n",
    "    decoder = Decoder(target_text_processor, target_vocab, target_vocab_size, units)\n",
    "\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.units = units\n",
    "    self.context_text_processor = context_text_processor\n",
    "    self.context_vocab_size = context_vocab_size\n",
    "    self.target_text_processor = target_text_processor\n",
    "    self.target_vocab = target_vocab\n",
    "    self.target_vocab_size = target_vocab_size\n",
    "\n",
    "  def call(self, inputs):\n",
    "    context, x = inputs\n",
    "    context = self.encoder(context)\n",
    "    logits = self.decoder(context, x)\n",
    "\n",
    "    #TODO(b/250038731): remove this\n",
    "    try:\n",
    "      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    return logits\n",
    "\n",
    "  def translate(self, texts, *, max_length=700, temperature=0.0):\n",
    "    # Process the input texts\n",
    "    context = convert_input(self.encoder,texts)\n",
    "    #batch_size = tf.shape(texts)[0]\n",
    "\n",
    "    # Setup the loop inputs\n",
    "    tokens = []\n",
    "    attention_weights = []\n",
    "    next_token, done, state = self.decoder.get_initial_state(context)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "      # Generate the next token\n",
    "      next_token, done, state = self.decoder.get_next_token(\n",
    "          context, next_token, done,  state, temperature)\n",
    "          \n",
    "      # Collect the generated tokens\n",
    "      tokens.append(next_token)\n",
    "      attention_weights.append(self.decoder.last_attention_weights)\n",
    "      \n",
    "      if tf.executing_eagerly() and tf.reduce_all(done):\n",
    "        break\n",
    "\n",
    "    # Stack the lists of tokens and attention weights.\n",
    "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
    "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
    "\n",
    "    result = self.decoder.tokens_to_text(tokens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 01:45:08.993804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:09.027359: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:09.027575: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:09.029051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:09.029409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:09.029633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:10.061530: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:10.061872: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:10.062184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 01:45:10.062417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2585 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n",
      "2023-04-18 01:45:10.690097: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:10.690256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:10.690338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:10.894723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:10.894914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:10.895065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.057426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:11.057528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:11.057605: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.169927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:11.171154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:11.171282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:11.171366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.240107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:11.241364: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:11.241463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:11.241554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.285158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:11.285326: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:11.285425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.374788: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:11.658532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:11.660537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:11.660668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:11.660791: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:11.893406: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.169722: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.246887: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:12.247077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:12.247250: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:12.519379: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.542694: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.607777: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.621924: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:12.837473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:12.837585: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:12.837663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:13.113959: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:13.184139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:13.184325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:13.184444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:13.541846: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:13.543050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:13.543138: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:13.543228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:13.622564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:13.622669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:13.622749: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:13.844273: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:13.844378: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:13.844451: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:14.175269: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:14.625772: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:14.626929: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:14.627012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:14.627088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:14.915914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:14.916059: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:14.916166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:15.009624: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.022905: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.043332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:15.044555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:15.044639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:15.044722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:15.092581: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.106486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:15.106584: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:15.106653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:15.164474: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.286269: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.296981: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.310504: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.539057: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.709680: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:15.709785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:15.709863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:15.884296: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:15.900916: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.094354: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.107739: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.255519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:16.256712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:16.256804: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:16.256883: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:16.441317: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.453120: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.511218: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:16.512365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:16.512452: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:16.512532: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:16.797841: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.903889: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.913248: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.932183: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.952801: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.963265: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:16.993952: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.091847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:17.091948: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:17.092018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:17.112098: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.123828: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.133679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:17.135039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:17.135143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:17.135246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:17.326582: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.639253: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.652015: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:17.909847: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_reversev2_grad_reversev2_reversev2_axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients_reversev2_grad_reversev2_reversev2_axis}}]]\n",
      "2023-04-18 01:45:17.911030: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:17.911119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:17.911247: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:18.006543: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:18.087822: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:18.099197: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:18.861611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_2_grad_concat_split_2_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_2_grad_concat_split_2_split_dim}}]]\n",
      "2023-04-18 01:45:18.861720: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_grad_concat_split_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_grad_concat_split_split_dim}}]]\n",
      "2023-04-18 01:45:18.861795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients_split_1_grad_concat_split_1_split_dim' with dtype int32\n",
      "\t [[{{node gradients_split_1_grad_concat_split_1_split_dim}}]]\n",
      "2023-04-18 01:45:18.880807: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 13 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:18.891806: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 46 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:19.111198: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond/while' has 14 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n",
      "2023-04-18 01:45:19.123621: W tensorflow/core/common_runtime/graph_constructor.cc:812] Node 'cond' has 4 outputs but the _output_shapes attribute specifies shapes for 48 outputs. Output shapes may be inaccurate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Translator at 0x7f704f5ecac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = tf.keras.models.load_model(\"nlp_model\", custom_objects={'Translator': Translator, 'tf_lower_and_split_punct': tf_lower_and_split_punct,'masked_acc': masked_acc, 'masked_loss': masked_loss})\n",
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dear francisco , we hope this message finds you well . as your solar power provider , we wanted to provide you with a report on the predicted solar power generation for your panels on may 28th , 2023 at 1900 . unfortunately , it looks like the solar power generated during this time will be quite low , estimated at 1 . 4 kilo watts . this is due to the predicted temperature value having a negative impact on your solar panels . we are also want to inform you that you can safely use your water heater and dishwasher during this time . as the temperature wont surpass the generated power , this means that some of your appliances may exceed the generated power . we recommend that you consider using your dishwasher at this time as it wont surpass the generated power . however , we would not be happy to contact us if you have any further questions or concerns regarding the information provided above . we take pride in providing efficient , reliable , and accurate solar power predictions to our clients . best regards , tenergito '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = load_model.translate(['7 February 2024 13 Rafael medium 8.0 hourly precipitation temperature negative impact negative impact 2.0 0.0 2.0 0.0 1.0'])\n",
    "\n",
    "print(len(result[0].numpy().decode()))\n",
    "result[0].numpy().decode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
