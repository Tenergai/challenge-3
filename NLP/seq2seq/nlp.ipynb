{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# set seeds for reproducability\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "# keras module for building LSTM \n",
    "from keras.models import Model\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Input, Concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.utils as ku\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./nlp_data.csv')\n",
    "#files = []\n",
    "#for file in data['filename']:\n",
    "#    with open('../corpus/'+file) as f:\n",
    "#        content = f.read()\n",
    "#    files.append(content)\n",
    "\n",
    "#data = data.assign(reports=files)\n",
    "\n",
    "report = data['report']\n",
    "data = data.drop('report',axis = 1)\n",
    "train_text, val_text, train_params, val_params = train_test_split(report, data, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_params(df,i):\n",
    "    params = df.iloc[i]\n",
    "    pre_params = []\n",
    "    # Preprocess the parameters\n",
    "    # Convert October to a number\n",
    "    pre_params.append(datetime.strptime(params['month'],'%B').month)\n",
    "    # Convert strings to numerical values\n",
    "    pre_params.append(float(params['day']))\n",
    "    pre_params.append(int(params['year']))\n",
    "    pre_params.append(int(params['hour']))\n",
    "    pre_params.append(float(params['solar_power_num']))\n",
    "    # Convert positive/negative contributions to one-hot encoding\n",
    "    if params['contri1'] == \"positive contribution\":\n",
    "        pre_params.append(1)\n",
    "    else:\n",
    "        pre_params.append(0)\n",
    "    # Convert the parameters to a numpy array\n",
    "    return np.array(pre_params)\n",
    "\n",
    "\n",
    "pre_params = np.array([preprocess_params(train_params, i) for i in range(len(train_params['day']))])\n",
    "\n",
    "val_pre_params = np.array([preprocess_params(val_params, i) for i in range(len(val_params['day']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(t for t in txt if t not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt  \n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to a token sequence \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "def generate_padded_sequences(input_sequences,total_words):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "corpus = [clean_text(x) for x in train_text]\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences,total_words)\n",
    "\n",
    "\n",
    "val_corpus = [clean_text(x) for x in val_text]\n",
    "val_inp_sequences, val_total_words = get_sequence_of_tokens(val_corpus)\n",
    "val_predictors, val_label, val_max_sequence_len = generate_padded_sequences(val_inp_sequences,val_total_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    input_text = Input(shape=(input_len,))\n",
    "    \n",
    "    # Define the embedding layer for the text input\n",
    "    x = Embedding(total_words, 10, input_length=input_len)(input_text)\n",
    "\n",
    "    # Define the LSTM layer\n",
    "    x = LSTM(100)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Define the output layer\n",
    "    output = Dense(total_words, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 245)]             0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 245, 10)           11230     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1123)              113423    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,053\n",
      "Trainable params: 169,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 33/938 [>.............................] - ETA: 1:22 - loss: 6.5440"
     ]
    }
   ],
   "source": [
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()\n",
    "\n",
    "test_scores = model.fit(predictors, label, epochs=50, verbose = 1)\n",
    "print(test_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    f.close()\n",
    "    \n",
    "with open('max_sequence_len.pkl', 'wb') as f:\n",
    "    pickle.dump(max_sequence_len, f)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-04-07 18:40:10      2185488\n",
      "config.json                                    2023-04-07 18:40:10         2348\n",
      "metadata.json                                  2023-04-07 18:40:10           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "with open('nlp_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('max_sequence_len.pkl', 'rb') as f:\n",
    "    max_sequence_len = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted=np.argmax(predicted,axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Precipitation Dear Maximize We Hope This Message Finds You Well As Your Solar Power Provider We Wanted To Provide You With Will Report On The Predicted Solar Power Generation For Your Solar Panels On October Affecting 2023 At Writing Oclock The Solar Power Generated From Your Solar Panels Is Predicted To Be Am Low At External Kilo Watts Due To The Hourly Precipitation Predicted If Having Will Negative Impact We Would Like To Using You That During This Time Your Air Conditioner May Exceed The Generated Power During This Time Additionally Your Water Heater And Air Conditioner A Definitely Exceed The Generated Power We Recommend That You While Inconvenience Power Still During This Time To Avoid Any Excited Please Significant Or Know Value You Have Any Questions Us Concerns About This Report Thank You For Choosing Or As Your Solar Power Provider Best Are Tenergito Help At Tenergito We Wanted To Provide You With Will Therefore Report On The Solar Power Generated By Your Solar Panels On Weather 22Nd 2024 At Taking Pm Based On Our Analysis We These That The Solar Power Generated A Be Medium At Leading Kilo Watts Due To The Predicted Daily Rain And Solar Radiation Values\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"hourly precipitation\", 200, model, max_sequence_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
