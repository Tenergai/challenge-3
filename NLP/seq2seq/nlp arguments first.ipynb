{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 19:37:49.701532: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 19:37:51.421011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pardalito/miniconda3/envs/meia/lib/\n",
      "2023-04-11 19:37:51.421188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pardalito/miniconda3/envs/meia/lib/\n",
      "2023-04-11 19:37:51.421205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# set seeds for reproducability\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "from numpy.random import seed\n",
    "set_random_seed(2)\n",
    "seed(1)\n",
    "# keras module for building LSTM \n",
    "from keras.models import Model\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Input, Concatenate\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.utils as ku\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./nlp_data.csv')\n",
    "#files = []\n",
    "#for file in data['filename']:\n",
    "#    with open('../corpus/'+file) as f:\n",
    "#        content = f.read()\n",
    "#    files.append(content)\n",
    "\n",
    "#data = data.assign(reports=files)\n",
    "data = data.values.tolist()\n",
    "new_data = []\n",
    "for i in range(len(data)):\n",
    "    new_data.append([str(data[i][1]) + ' ' + str(data[i][2]) + ' ' + str(data[i][3]) + ' ' + str(data[i][4]) + ' ' + str(data[i][5]) + ' ' + str(data[i][6]) + ' ' + str(data[i][7]) + ' ' + str(data[i][8]) + ' ' + str(data[i][9]) + ' ' + str(data[i][10]) + ' ' + str(data[i][11]) + ' ' + str(data[i][12]) + ' ' + str(data[i][13]) + ' ' + str(data[i][14]) + ' ' + str(data[i][15]) + ' ' + str(data[i][16]) + ' ' + str(data[i][17])])\n",
    "\n",
    "report = pd.DataFrame(new_data, columns=['reports'])\n",
    "report = report['reports']\n",
    "train_text, val_text = train_test_split(report, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35     12 August 2023 12 Ana very high 5.667 temperat...\n",
       "11     17 December 2023 8 Ricardo very low 0.16 solar...\n",
       "29     23 February 2023 10 Ana medium 6.0 hourly prec...\n",
       "0      7 October 2023 15 Ema high 10.143 dewpoint nan...\n",
       "159    11 March 2023 17 Rafael low 1.2 solar radiatio...\n",
       "                             ...                        \n",
       "137    8 January 2023 11 Ana medium 8.0 daily rain na...\n",
       "72     4 September 2023 13 Franciso medium 3.133 temp...\n",
       "140    26 December 2024 19 Diana very low 1.0 hourly ...\n",
       "235    5 September 2023 18 Ricardo medium 2.867 humid...\n",
       "37     5 June 2024 13 Diana medium 6.286 hourly preci...\n",
       "Name: reports, Length: 204, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = \"\".join(t for t in txt if t not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt  \n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to a token sequence \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "def generate_padded_sequences(input_sequences,total_words):\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "    \n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "corpus = [clean_text(x) for x in train_text]\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences,total_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    input_text = Input(shape=(input_len,))\n",
    "    \n",
    "    # Define the embedding layer for the text input\n",
    "    x = Embedding(total_words, 10, input_length=input_len)(input_text)\n",
    "\n",
    "    # Define the LSTM layer\n",
    "    x = LSTM(100)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "\n",
    "    # Define the output layer\n",
    "    output = Dense(total_words, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 19:37:54.670405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:54.684551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:54.685348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:54.686347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 19:37:54.687773: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:54.688328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:54.688727: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:55.772028: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:55.772365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:55.772573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 19:37:55.772732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2619 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 with Max-Q Design, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 264)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 264, 10)           11340     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1134)              114534    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 170,274\n",
      "Trainable params: 170,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 19:37:59.297747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-04-11 19:38:00.340271: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fa5ee205840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-11 19:38:00.340331: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 with Max-Q Design, Compute Capability 7.5\n",
      "2023-04-11 19:38:00.349444: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-11 19:38:00.512196: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060/1060 [==============================] - 45s 38ms/step - loss: 5.1617\n",
      "Epoch 2/50\n",
      "1060/1060 [==============================] - 18s 17ms/step - loss: 4.0077\n",
      "Epoch 3/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 3.1426\n",
      "Epoch 4/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 2.6770\n",
      "Epoch 5/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 2.3924\n",
      "Epoch 6/50\n",
      "1060/1060 [==============================] - 20s 19ms/step - loss: 2.2052\n",
      "Epoch 7/50\n",
      "1060/1060 [==============================] - 20s 19ms/step - loss: 2.0627\n",
      "Epoch 8/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.9555\n",
      "Epoch 9/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.8620\n",
      "Epoch 10/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.7846\n",
      "Epoch 11/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.7200\n",
      "Epoch 12/50\n",
      "1060/1060 [==============================] - 18s 17ms/step - loss: 1.6588\n",
      "Epoch 13/50\n",
      "1060/1060 [==============================] - 14s 13ms/step - loss: 1.6124\n",
      "Epoch 14/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.5650\n",
      "Epoch 15/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.5222\n",
      "Epoch 16/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.4855\n",
      "Epoch 17/50\n",
      "1060/1060 [==============================] - 14s 14ms/step - loss: 1.4507\n",
      "Epoch 18/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.4222\n",
      "Epoch 19/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.3939\n",
      "Epoch 20/50\n",
      "1060/1060 [==============================] - 20s 19ms/step - loss: 1.3666\n",
      "Epoch 21/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.3408\n",
      "Epoch 22/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.3153\n",
      "Epoch 23/50\n",
      "1060/1060 [==============================] - 17s 17ms/step - loss: 1.2924\n",
      "Epoch 24/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.2709\n",
      "Epoch 25/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.2551\n",
      "Epoch 26/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.2312\n",
      "Epoch 27/50\n",
      "1060/1060 [==============================] - 19s 18ms/step - loss: 1.2143\n",
      "Epoch 28/50\n",
      "1060/1060 [==============================] - 18s 17ms/step - loss: 1.1981\n",
      "Epoch 29/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.1788\n",
      "Epoch 30/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.1640\n",
      "Epoch 31/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.1522\n",
      "Epoch 32/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.1332\n",
      "Epoch 33/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.1152\n",
      "Epoch 34/50\n",
      "1060/1060 [==============================] - 19s 17ms/step - loss: 1.1015\n",
      "Epoch 35/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.0952\n",
      "Epoch 36/50\n",
      "1060/1060 [==============================] - 18s 17ms/step - loss: 1.0817\n",
      "Epoch 37/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 1.0741\n",
      "Epoch 38/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.0538\n",
      "Epoch 39/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.0402\n",
      "Epoch 40/50\n",
      "1060/1060 [==============================] - 17s 16ms/step - loss: 1.0347\n",
      "Epoch 41/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.0218\n",
      "Epoch 42/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 1.0160\n",
      "Epoch 43/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 0.9986\n",
      "Epoch 44/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 0.9929\n",
      "Epoch 45/50\n",
      "1060/1060 [==============================] - 16s 15ms/step - loss: 0.9804\n",
      "Epoch 46/50\n",
      "1060/1060 [==============================] - 15s 14ms/step - loss: 0.9811\n",
      "Epoch 47/50\n",
      "1060/1060 [==============================] - 13s 13ms/step - loss: 0.9621\n",
      "Epoch 48/50\n",
      "1060/1060 [==============================] - 13s 13ms/step - loss: 0.9503\n",
      "Epoch 49/50\n",
      "1060/1060 [==============================] - 14s 13ms/step - loss: 0.9413\n",
      "Epoch 50/50\n",
      "1060/1060 [==============================] - 14s 13ms/step - loss: 0.9351\n",
      "<keras.callbacks.History object at 0x7fa863b8d180>\n"
     ]
    }
   ],
   "source": [
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()\n",
    "\n",
    "test_scores = model.fit(predictors, label, epochs=50, verbose = 1)\n",
    "print(test_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "......input_layer\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-04-11 19:52:02      2070008\n",
      "config.json                                    2023-04-11 19:52:02         2791\n",
      "metadata.json                                  2023-04-11 19:52:02           64\n"
     ]
    }
   ],
   "source": [
    "with open('nlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    f.close()\n",
    "    \n",
    "with open('max_sequence_len.pkl', 'wb') as f:\n",
    "    pickle.dump(max_sequence_len, f)\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-04-11 19:52:02      2070008\n",
      "config.json                                    2023-04-11 19:52:02         2791\n",
      "metadata.json                                  2023-04-11 19:52:02           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "......input_layer\n",
      ".........vars\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "with open('nlp_model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open('max_sequence_len.pkl', 'rb') as f:\n",
    "    max_sequence_len = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted=np.argmax(predicted,axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if predicted == index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 July 2023 20 Leticia Very High 1342 Daily Rain Solar Radiation Significant Negative Impact Significant Negative Impact 2 2 2 20 20 00 00 Dear Diana We Hope This Message Finds You Well As Your Solar Power Provider We Wanted To Provide You With Some Important Information Regarding The Solar Power Generated By Your Solar Panels On July 24Th 2024 At 1900 We Predict That Your Solar Panels Will Generate A High Amount Of Power Specifically 272 Kilo Watts This Is Due To The Positive Contribution Of The Predicted Temperature Value And Temperature Predicted Value This Means That You Can Use Your Dishwasher And Water Heater Without Exceeding The Generated Power However We Advise Against Using Your Washing Machine As It Might Exceed The Generated Power We Hope This Information Is Helpful And You To You And That You Are Able To Enjoy The Benefits Of Your Solar Panels And We Hope You Find This Report Helpful And Informative As Always If You Have Any Questions Or Concerns Please Dont Hesitate To Reach Out To Us Best Regards Tenergito Team Team Best Regards Tenergito Team Best Regards Tenergito Team Team Will Be Committed To Assist You In Your Energy Goals In The Most Efficient Way Possible Best Regards Tenergito And Solar Power Generation Best Regards Tenergito Team Best Regards Tenergito\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"3 July 2023 20 Leticia very high 1342 daily rain solar radiation significant negative impact significant negative impact 2 2 2\", 200, model, max_sequence_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
